#  Gu铆a de M茅tricas para Evaluaci贸n de Traducci贸n Autom谩tica

##  M茅tricas estad铆sticas: r谩pidas pero sin contextualizaci贸n sem谩ntica, ayudan de complemento

### 1. **BLEU (Bilingual Evaluation Understudy)**
 **Descripci贸n**: Eval煤a la precisi贸n de n-gramas (palabras o secuencias) comparando con traducciones de referencia. Basicamente, compara la traducci贸n hecha por humanos y la nuestra y hace un c谩lculo. Sirve para textos cortos porque en el momento que ve un sin贸nimo falla

- **Caso de uso ideal**: Evaluaci贸n general de traducciones est谩ndar.
- **Rango de valores**: `0.0` (p茅simo) a `1.0` (perfecto).  
  - *Ejemplo t铆pico*:  
    - < 0.3: Traducci贸n inaceptable  
    - 0.3-0.5: Calidad b谩sica  
    - 0.5-0.7: Buena calidad  
    - > 0.7: Excelente calidad
- **Requisitos**: Requiere texto de referencia.


### 2. **METEOR**
 **Descripci贸n**: Es como BLEU pero m谩s potente porque considera sinonimos, stems y alineaci贸n de palabras, adem谩s tiene m谩s correlaci贸n con traduccione humanas.
- **Caso de uso ideal**: cuando queremos mas precision y recall.
- **Rango de valores**: `0.0` (p茅simo) a `1.0` (perfecto).  
  - *Ejemplo t铆pico*:  
    - < 0.3: Traducci贸n inaceptable  
    - 0.3-0.5: Calidad b谩sica  
    - 0.5-0.7: Buena calidad  
    - > 0.7: Excelente calidad
- **Requisitos**: Requiere texto de referencia.

### 3. **ROUGE-N**
 **Descripci贸n**: Esta m茅trica mide la cobertura del contenido mediante la superposici贸n de n-gramas.
- **Caso de uso ideal**: Medir la cobertura de palabras clave.
- **Rango de valores**: `0.0` (p茅simo) a `1.0` (perfecto).  
  - *Ejemplo t铆pico*:  
    - < 0.3: Traducci贸n inaceptable  
    - 0.3-0.5: Calidad b谩sica  
    - 0.5-0.7: Buena calidad  
    - > 0.7: Excelente calidad
- **Requisitos**: Requiere texto de referencia.


##  M茅tricas neuronales: modelos entrenados que miden la calidad de traducci贸n 

### 1. **COMET**
**Descripci贸n**: Modelo neuronal que evalua la calidad de la traducci贸n teniendo en cuenta el contexto. Ideal en relaci贸n sem谩ntica
- **Caso de uso ideal**: evaluaci贸n profesional muy parecida al humano.
- **Rango de valores**: `0.0` (p茅simo) a `1.5` (perfecto).  
  - *Ejemplo t铆pico*:  
    - < 0.5: Traducci贸n deficiente  
    - 0.5-0.8: Calidad aceptable  
    - 0.8-1.2: Buena calidad  
    - > 1.2: Excelente
- **Requisitos**: Puede funcionar con y sin referencia. Si es sin referencia el score maximo es 1.3 y con referencia 1.5 .


### 2. **BLEURT**
**Descripci贸n**: M茅trica basada en BERT fine-tuned para la evaluacion de metricas en traducci贸n
- **Caso de uso ideal**: Evaluar la calidad sem谩ntica y naturalidad del texto
- **Rango de valores**: `-2.0` (p茅simo) a `2.0` (perfecto).  
  - *Ejemplo t铆pico*:  
    - < 0.0: Baja calidad
    - 0.0-1.0: Calidad media
    - 1.0: Alta calidad
- **Requisitos**: Funciona con referencia


### 2. **BERTscore**
working

